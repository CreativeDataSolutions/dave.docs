[["index.html", "DAVe.docs 1 Getting Started 1.1 Quickstart 1.2 Workflows", " DAVe.docs 1 Getting Started DAVe: Data Analysis and Visualization engine Welcome to DAVe, the application which interactively combines statistics, clustering, data explortaion and visualization with machine learning, functional and network analysis to create information and context rich mapped networks. The following manual describes a selection of available workflows. Get ready to connect your data with context! DAVe is comprised of 9 modules covering: data, pre-processing, statistics, clustering, dimensional reduction, pathway analysis, predictive modeling, network analysis and reporting domains. Each module may contain calculate/summary, explore, plot and report components. Calculate and Summarize This tab is used to set the method options and view the results summary and tabular output. Explore Interactively explore the results. Plot View and tune your data visualizations. Report Create data analysis summaries and reproducible reports. 1.1 Quickstart DAVe is comprised of individual modules which can be linked to create a variety of unique data analysis workflows. The Global Utilities include Data and Report and provide an overview of objects shared by the Data Analysis Tools. The majority of analyses start with data upload using the Data module and then preparation using Preprocess. Check out the Analysis Workflows section for more examles. A Select Modules The navigation bar is used to select different analyses. Each analysis may also have sub-options. Typical workflows will include choosing modules from the nav bar progressing from left to right and while optimizing each step with sub analyses by progressing through each modules method controls from top to bottom. See the Analysis Workflows section for details how to save and propogate results between induvidual modules. B Module Controls The sidebar is used to select analyses methods, tune visualizations and specify report options. C Progress Analyses The tabpanel can be used to switch between calculation, interactive exploration, static plotting and report generation. Use calculate to select method options and generate data objects. Explore provides interactive visualizations, while plot is used to tune how the visualizations will appear in the report. The report tab is used to collect all methods, results and plot settings and generate a report of methods and results. The report may also include additional information not present in the previous tabs and can be dynamically populated based on user selected visualizations. All analyses report results can be combined and further manipulated in navbar Report module. D Results and Methods This is the main panel where calculation, exploration, plotting and report results will be output to. Results may include both static and interactive results which can be manipulated further. E Help Select this icon to to view the help menu for each selected analyses. 1.2 Workflows Each module shares internal workflow elements. The analyses proceed using the calculate tab to set the methods and get results. The results can be visualized using static plot or interactive explore tabs. The methods, results and created visualizations can be summarized in the report. This can be done iteratively to explore and refine the analysis results and summaries. Once the results reached the data object can be saved using the controls at the bottom of the calculate menu. 1 Upload Data Load data from a .csv or saved project. 2 Prepare Data Use the Preprocess module to specify sample meta data and merge with variable information. Review and impute missing values. 3 Save Results Each modules calculations and results can be saved and used in further analyses. The save controls found at the bottom of each module's controls menu can be used to specify various parameters to add to the global data sets. 4 Generate Reports Each modules results, methods and visualizations can be saved to the analysis report. Individual module's reports can be combined and further modified using the global report module. 5 Statistical Analysis The statistics module can be used to compare changes in variables among groups of samples and calculate summary statistics. 6 Pathway Analysis The p-values and fold changes calculated statistics module can be used to calculate pathway enrichment. The enriched pathways can be visualized to show the direction of significant changes in variables mapped to biochemical pathways. 7 Clustering Use the cluster module to identify groups of related samples or variables. Use Hierarchical Clustering (HCA) on the full data or sample and variable correlation. Visualize meta data and cluster relationships with heatmaps and dendrograms. 8 Dimensional Reduction Use the multivariate module to calculate lower dimensional summaries of multivariate data. Use Principal Components Analysis (PCA) to visualize the major modes of variance in samples, variables and their correlations. 9 Predictive Modeling Use the model module to calculate machine learning (ML) models to identify predictive relationships for groups or continuous variables. Use auto ML to optimize and tune models while choosing from over 200 available algorithms. Carry out feature selection to rank important variables for explaining the model performance. 10 Network Analysis and Mapping Use the network module to identify biochemical, structural similarity and regularized correlation relationships between variables. Use the network module to combine the results from other modules by using network mapping to visualize meta data, statistical, clustering, dimensional reduction, predictive modeling and pathway analysis results. Use highly interactive network visualizations to fine tune publication quality static graphics. "],["modules.html", "2 Modules 2.1 Data 2.2 Preprocessing 2.3 Statistics 2.4 Clustering 2.5 Multivariate Analysis 2.6 Pathway Analysis 2.7 Predictive Modeling 2.8 Network Analysis", " 2 Modules 2.1 Data 2.1.1 Summary The Data module is used to load, overview and manage datasets used by all other modules. The following is an example of how to format data for analysis in DAVe. To load the tutorial data select the Data module &gt;&gt; then Load on the sidebar &gt;&gt; Data type: examples &gt;&gt; load. Loading the example data will add the dave_ and dave_var_meta data sets which are examples of how to format the numeric data, sample (row) meta data and variable (column) meta data. Notice that dave_ contains both information about the samples (columns A to C) which describes each of the measurements. For example, the first row contains information about the sample label: sample1, its class: non-diabetic and age: old. The measured values for sample1 start in column D (e.g. var1, var2, etc). The measured variables can correspond to any numeric data to be used for the analysis while the sample meta data contained in the first three columns can be used to construct statistical and machine learning models and annotate visualizations. To merge the sample meta data and numeric data we need to specify the index shared by the dave_ and dave_var_meta data components. The index corresponding the mapping between the two data sets is defined in the ID column in dave_var_meta. Note: while this column can have any name, it needs to contain the exact column name(s) specified for the numeric data in dave_. For example, the first row in dave_var_meta describes the numeric variable named var1 in the dave_ data. Important: it is recommended to use strings with no spaces and special characters (e.g. var1 or measurement_1) instead of numeric values to name the numeric data and the index. Next use the Preprocess module to merge the two dataset. 2.1.2 Reference This module is used to overview and manage data and metadata objects. Data management To get started format your data into two parts as shown below and then follow allong with the instructions in preprocess >> merge to create an analysis ready data object. Methods The data should be formated into two parts 1) the main data containing sample descriptions and numeric variable data and 2) variable meta data. The main components include the ability to select and view the data. Selected data is shown in the overview. Data can be uploaded in the following formats: .csv, project or example. Data can be saved as a .csv for download or a project which can be loaded later. Deletion of data objects can be done here. 2.2 Preprocessing 2.2.1 Summary 2.2.1.1 Merge The preprocess merge module is used to select row meta data components from dave_ and specify the index to merge the numeric data with dave_var_meta which contains information about each of the columns or measurements. Select the Samples menu in the sidebar then the column names for the variables which contain the sample meta data. Next use the Variables menu to select the variable meta data: dave_var_meta and specify the column name for the index: ID to merge with dave_. Note: in some cases, you may only have information about the variables and no numeric sample data. For example, you could have already calculated statistical significance for variables or have other information you want to use to conduct pathway, network or other analyses. In this case, change the Data type in the sidebar to variables. Next click the calculate button to merge the data. This will output the merge methods used and results. The plot and explore tabs can be used to visualize the results. Next, select Save menu in the sidebar, choose a name for your new data and save the data to use in other analyses. This will add the merged data to the global environment which then can be used for further analyses. 2.2.1.2 Filter missing values The preprocess missing is used to overview, remove and impute missing values in the numeric data. Important : rows or columns a with too many missing values or a missing pattern biasing a factor in the sample meta data should be removed or imputed. The Filter menu in the sidebar can be used to evaluate missing values across all variables. Missing values can be evaluated based on a grouping variable in the sample meta data e.g. class: diabetic or non-diabetic to remove missing patterns which can bias further analyses comparing the two groups. The selection shown above will remove any variable(s) which contain  50% missing values for either diabetic or non-diabetic samples. Select calculate and then use the plot and explore tabs to visualize the results. The above visualization displays the persent missing valuse in variables overall and for each group. The above visualization shows sample(s) with missing values. Important: the remaining missing values should be replaced or imputed by selecting the impute menu in the sidebar. A simple method to impute missing values is to replace them with a specific value (e.g. 0) or a summary metric based on present values. If missing values are present due to analytical reasons like the measurement was below the limit of detection then a simple imputation approach like replacing missing values with the minimum of present values for each column reduced by 60% (e.g. missing values become the minimum value for each column multiplied by 0.6). Once all the methods are set next use the calculate button to view the results. Use the sidebar save menu to save the results for further analyses. Note: dont change the name of the data to easily keep all module results combined. 2.2.2 Reference /* zoom on click hacks https://stackoverflow.com/questions/39858998/zoom-in-and-out-on-mouse-click-with-css */ .left_panel { left:-8.33%; text-align: left; float: left; width:50%; z-index:-10; } .right_panel { left:31.25%; top: 75px; float: right; text-align: right; z-index:-10; width:50%; } .zoom_plot { transition: transform .5s; /* Animation */ } .zoom_plot:hover { transform: scale(1.5); /* (150% zoom - Note: if the zoom is too large, it will go outside of the viewport) */ transition-delay: 1.5s; } This module is used to merge, filter and prepare the data for analysis. Merge Merge is used to identify experimental design factors and merge numeric and variable metadata. Methods Select sample meta data (e.g. non-numeric descriptors of the experimental design) which will be added to the _row_meta object and made available to use in visual mapping and analysis/calculation controls. Identify and row meta data. Identify and add column or measurement meta data, wherein ID sets the unique row identifier (e.g. row number). Results Explore and Plot Visualize a summary of the merged data. Save Use save to create a data set which will be used for further analyses. Filter Filter can be used to identify and remove variables with missing values. Specify a factor group of interest and the missing cutoff or percent acceptible missing for each level in the group. It is also useful to remove non-informative varibles or those with a standard deviation of zero (remove zero variance). Methods Remove error prone variables with too many missing values or zero variance. Optionaly select groups of samples to evaluate missing values. Impute all missing values in the data. Replace based on a variery of sumaries based on the presnt values. Results Explore and Plot View missing data for each sample and variable, overall and by class. Missing or zero variables shown in red are arranged based on their sample (row) and variable (column) number. Flagged variables, or those containing greater or equal percent zero or missing values than the missing cutoff are shown in red for each level of a group group. 2.3 Statistics 2.3.1 Reference Statistics This module is used to carry out statistical analyses, identify and filter the data based on significant differential expression. Kruskall-Wallis (two-class comparison of means) This is a non-parametric test for differences in means between two groups. This test does not assume normality and can be robust to outliers when testing for differences in means between two groups with small samples sizes. This module can also be used to identify differentially expressed variables between groups and create filtered datasets based on the test p-values. Methods Identify experimental design factor(s) to use for tests and specify variable meta data. Select significance level (alpha) to use in visualizations and filter the data. Results Explore and Plot Create a volcano plot to visualize the relationship between variable fold-changes between groups and test p-values. Identify variables with large fold-changes between groups and low p-values. Select one or many variables to generate violin density plots. Explore variable distributions among groups. Use plot to view many variables and overview the plot style for the report. Save Save results and optionally remove non-significant variables by selecting keep selected. 2.4 Clustering 2.4.1 Reference Cluster This module is used to identified clusters of related groups of samples and variables. Hierarchical cluster analysis (HCA) This module is used to carry out hierarchical cluster analysis (HCA) on samples and variables. HCA distance and agglomeration methods can be used to organize the input based on similarity and identify clusters of closely related samples or variables based on the raw data or correlations. Methods Use the nodes menue to specify if samples or variables will be clustered. You can additionally specify names used for labels and annotations used for displaying group metadata. The methods menue is used to optionally specify a correlation method, set HCA distance and linkage methods and select the number of clusters. Results Explore and Plot Select dendrogram plot type to focus on the relationship between HCA ordering and metadata set in the node >> annotations menue. Select explore and heatmap plot type to overveiw sample and/or variable similarities and groups. Click and drag the mouse on the heat map to zoom in. Use plot >> heatmap to visualize heatmap and metadata. 2.5 Multivariate Analysis 2.5.1 Reference Multivariate This module supports dimensional reduction and projection pursuits. Principal Components Analysis (PCA) Principal components analysis (PCA) can be used to summarise the major modes of variance in the data by fewer and uncorrelated principal components (PCs). It is helpful to analyze how sample and variable meta data is related to PCA sample scores and variable loadings. Methods Specify the PCA method and normalize the data through centering and scaling. Results Overview methodsand the variance explained by the PCA model. Explore and Plot Select from a variety of plot types. The screeplot shows the variance explained by each PC. The dashed line marks the 1 % variance limit below which components can be ommited. Use cummulative screeplot to view the total % variance explained. The dashed line shows the boundary where 80% of the original variance in the data has been captured by the PCA model. The diagnostics plot can be used to identify moderate and extreme sample outliers. Large sample leverage denotes a large influence of the samples variance to the identification of the PC components (outliers). The DmodX or highlights moderate multivariate sample differences. Samples showing both high leverage and DmodX shoudl be investigated further. Sample scores display multivariate similarities through proximity to other samples in the PCA space. The loadings plot displays variable similarities. The plotting menue for scores and loadings can be used to select PCs to view, map meta data to plot colors and group boundaries showing the Hoettlings T2 ellipse and modify plot asthetics. The biplot can be used to simultaneously visualize sample scores and loadings over layed on top of each other. Variables with extreme loadings (large positive or negative x/y position) have the largest effects on the sample scores (may correspond to low or high values among samples with similairly extreme scores compared to others). 2.6 Pathway Analysis 2.6.1 Reference Pathways This module is used to test for significant enrichment in biological pathways and visualize the results. Pathway enrichment and visualization Pathwayenrichment is calculated using the hypergeometric test. This module uses the KEGG reference organism (ko) database. Methods Select the name of the column withKEGG id for each variable. Filter which variables will be tested for pathway enrichment based on statistical test p-values and significance cut off. Filter enrichment results based on the p-value cutoff and false dicovery rate (FDR) adjustment. Results Overview the enrichment test methods and tabular results where: map is the KEGG pathway map id, n_hits is the number of significant variables from this pathway, n_cpd the number of compounds in the pathway and prct is the percent of enriched variables compared to total pathway variables. Selection of interesting pathways to investigate further could involve: 1) verifying that the pathway has a moderate minimum number of variables (e.g. > 10) 2) identifying low p-value and high prct enriched pathways 3) visualizing the network topology of enriched variables in the pathway (e.g. look for metabolic proximity of cha ges which may signify a functional module) . NOTE: Some very large and generic pathways such as Metabolic pathways can take a few minutes to render. Explore and Plot Select pathway name and identify the column to use as the fold-change to view variable changes mapped to the pathway. The fold-changes normalized to between -1 and 1 are mapped onto pathway entities as described in the color bar in the top right corner. Report Select the number of top pathways (based on p-value) to show in table outputs and which pathways to show visualizations of. 2.7 Predictive Modeling 2.7.1 Reference Predictive modeling Create and optimize machine learning models for classification and regression tasks. Train Train is used to fit, optimize and validate models. Methods Selecting the type of model you would like to create classification or regression will toggle the available variables to predict. Use the filter menu selected to specify which variables should be included in the model based on criteria generated in other modules (e.g. statistical and feature selection). The model menu is used to specify a single or multiple models to fit to the data. The model hyperparameters can be automatically tuned based on grid size which defines the number or random setting to test. Specific model hyperparameters can be specified using the manual setting. Note when fitting multiple models tuning will be done in the auto mode. The optimize for is used to specify if you want to select the best model based on performance on the training or held out test data (recommended). This menu is used to specify the training and test data and model cross-validation parameters. Similar to the model>>tune the cross-validation parameters can be manually or automatically set. For example, the selections shown in the example will randomly select 70% of the data (samples) to fit the model which will then be validated on the 305 held out or test data. The model will be internally cross-validated by splitting the training data into 7 folds and then leaving out each fold during the model fit and then testing the performance on the held-out fold. This process will be repeated 3 times and the performance on the training data will be summarized over all the results. Results Explore and Plot Model performance for the training and test data and training time can be compared. This plot is used to visualize the impact of hyperparameters on model performance. Identify the proportion of miss classified samples. Visualize variable's importance or contribution to the model's performance. Importance for multiple models is calculated based weighted metric of the models performance and each variables importance in the model. Importance based on multiple models displays the variables consensus rank (y-axis) across all models and the actual importance in the single highest performing model (x-axis). Feature selection Feature selection is used to identify variables which maximize model performance. Optimal variables are identified using recursive feature elimination wherein many models are built from subsets of variables and an optimal model is identified based on which subset yielded the highest performing model. Methods The data menu is used to specify the model type and select target and predictor variables. The optimize menu is used to specify the algorithm used for the selection. The metric specifies which performance criteria will be used to identify the optimal subset of variables. The validate menu is used to specify the model cross-validation parameters and size of the automatic hyperparameter tuning grid. Results Explore and Plot This visualization displays model performance (y-axis) based on the subset of variables (x-axis). The optimal model is highlighted in red. The plot controls can be used to specify which model metric will be used for the visualization (use calculate to optimized subsets for that metric). The optimal variables can be selected based on the subset function. Options include PickSizeBest which specifies the subset which maximized or minimized the chosen performance metric or PickSizeTolerance which allows for models with less parameters (variables), which are also worse than the optimal model. The accepted decrease in performance is specified as a percent of the metric in tolerance. This visualizations shows the selected variables (red) importance compared to those which were removed (blue). Save Add selected features filter to the row_metadata or remove all non-selected variables from the data set keep selected. Common workflows might include feature selection followed by training wherein the rfe_selected filter can be used to select variables in the data >> filter >> selected menu (see here ). 2.8 Network Analysis 2.8.1 Summary The network module provides tools to calculate a variety of networks including: Correlation and regularized partial correlation Biochemical relationships Structural similarity The separately calculated networks can be merged and visualized or exported for visualization in other tools. Enrich combine, customize and visualize networks Biochemical networks To calculate biochemical networks, choose the Biochemical item from the network navbar. Then select the column name which contains KEGG identifiers for variables. Select the calculate button and overview the results. Save the calculated network for export or to combine with other results. Structural similarity To calculate metabolite relationships based on structural similarity choose the Structural item from the network navbar. Then select the column name containing PubChem CIDs (chemical identifiers). Important:, supplying non-valid CIDs or related SIDs (Structure Identifiers) may cause method failures or incorrect results. You can validate the CIDs through the pubchem website or use the translation module. Once the identifier is selected click the calculate button and overview the results. Note first time calculations for metabolites not present in your DAVe environment may take a moment to download and process but will be cached to your local database and be quickly retrieved next time. A common approach is to remove variables with score  0.7. However, this may omit metabolites with weak relationships from the network. Currently, inclusion of multi-filter criteria needs to be done outside of DAVe. Use the visualize menu in the navbar to filter connections based on the tanimoto similarity score. In the visualize tab select the edges menu from the sidebar. The item greater than and change the value to 0.7. Plot the results to apply the filter to the network. View the updated results in the calculate tab and save the network. Note, the edges can be saved unfiltered and then formatted outside of DAVe. Save the calculated network for export or to combine with other results. Enrich Use the enrich menu to combine, format and visualizenetworks. Combine multiple networks into one. Select networks calculated from the same data source or sharing a network index. After the networks are selected click the calculate button and overview the results. Save the results to visualize or export. Export network results Navigate to the Data navbar menu and select the network data fropm the Datasets sidebar menu. The _edges and _nodes contain the edge list and node attributes, respectively. Select each item one by one and use the save menu in the sidebar to export as .csv files. 2.8.2 Publication quality networks Creating networks in Cystoscape The following example shows how to use Cytoscape (v3.7.2) to create publication ready networks from assets calculated in DAVe. This example will use two components the edge_list and the node_data files. edge_list.csv node_data.csv Upload edge_list In cytoscape select File &gt;&gt; Import &gt;&gt; network from File Upload and then select the edge_list.csv file. Set from and to columns from set to Source Node to set to Target Node Select OK once the source and target columns are identified. Overview network Upload node _data. Select File &gt;&gt; Import &gt;&gt; Table from File Select the ID column as the variable Key The uploaded node attributes should now be available to edit the network node and edge visual properties. Specify the node and edge visual properties. Take a look at the example cytoscape.cys file for how each of the data columns were mapped to the network. 2.8.3 Reference Calculate and visualialize complex networks. Use network mapping to integrate your statistical, functional and machine-learning results.Current network options include: correlation and partial correlation, biochemical relationships, structural similarity and network mapping and visualization. Empirical networks This module is used to calculate and regularized correlation networks. Methods Select correlation type and if p-valuse should be False discovery rate corrected. Select regularizationm method based on rotation information criterion (ric), stability approach to regularization selection (stars) or extended Bayesian information criterion (ebic). Results Get methods and summary for the calculated network. Biochemical networks This module is used to calculate and biochemcial networks. Metabolomic precursor to product relationships are based on KEGG identifiers. Methods Select KEGG (https://www.genome.jp/kegg/) identifier column name in the data. Results Get methods and summary for the calculated network. Structural similarity networks This module is used to calculate and structural simialrity networks. Metabolite structural similarities are calculated based on overlap in Pubchem structural fingerprints defined by compound identifiers or CID (see more: https://pubchem.ncbi.nlm.nih.gov/). Methods Select Pubchem CID (https://pubchem.ncbi.nlm.nih.gov/search/help_search.html) identifier column name in the data. Results Get methods and summary for the calculated network. Enrich networks This module is used to combine and visualize networks. Methods Select networks to combine and visualize. Update network node attributes based on another compatible data set. Results View combined network summary. Visualize networks Use network mapping to plot and enrich networks. Methods Visualize variable information through annotation of network node properties such as: name, color, size and shape. Visualize and modify node attributes. Modify and filter edges or relationships. Customize network global properties. Visualize and modify node attributes. Interactive network with zooming and hover. Dynamic network with node manipulation and custom controls. Investigate network topology. Customize network global properties. "]]
